============================================================
MACHINE UNLEARNING FULL EXPERIMENT SUITE
5 Experiments: HP + TOFU (grad_diff, grad_ascent, KL, idk)
============================================================

[1/5] Starting Harry Potter Experiment...
Models: Llama-2-7b-chat-hf -> Llama2-7b-WhoIsHarryPotter


============================================================
Started: 20251215_155418
============================================================

============================================================
PHASE 1: Data Loading & Activation Extraction
============================================================

Loading datasets...
Loading Harry Potter dataset from MUSE-Books (subset: knowmem)...
Available splits: ['retain_qa_icl', 'retain_qa', 'forget_qa', 'forget_qa_icl']
Using 'forget_qa' split with 100 samples
Successfully loaded 100 Harry Potter queries
Loaded 100 total queries

--- Extracting from BASE model ---
Extracting activations from layers [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
Loading model: meta-llama/Llama-2-7b-chat-hf
Saved base activations to outputs_hp_full/base_activations.pkl

--- Extracting from UNLEARNED model ---
Extracting activations from layers [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
Loading model: microsoft/Llama2-7b-WhoIsHarryPotter
Saved unlearned activations to outputs_hp_full/unlearned_activations.pkl

============================================================
PHASE 2: Geometric Feature Computation
============================================================

--- Computing features for BASE model ---
Saved base features to outputs_hp_full/base_geometric_features.csv

--- Computing features for UNLEARNED model ---
Saved unlearned features to outputs_hp_full/unlearned_geometric_features.csv

Base Feature Statistics:
       local_density_mean  ...  cross_layer_consistency_min
count          100.000000  ...                   100.000000
mean             1.591097  ...                     0.541504
std              0.300914  ...                     0.028534
min              1.282471  ...                     0.458252
25%              1.409526  ...                     0.530273
50%              1.504791  ...                     0.550537
75%              1.674666  ...                     0.560181
max              2.707021  ...                     0.598145

[8 rows x 24 columns]

============================================================
PHASE 3: Vulnerability Testing
============================================================

--- Part A: Base Model Accuracy (sampling baseline) ---
Saved base model accuracy to outputs_hp_full/base_accuracy.csv
Base model CAF: 0.119

--- Unloading base model to free GPU memory ---
GPU memory freed. Available: 5.35 GB

--- Part B: Unlearned Model Retention (sampling, no steering) ---
Saved unlearned retention results to outputs_hp_full/direct_retention.csv
Unlearned model retention CAF: 0.043

--- Comparison ---
Base model CAF:             0.119
Unlearned model retention:  0.043
Unlearning effectiveness:   0.957

--- Part C: Attack Method = 'all' ---

--- Activation Steering Attack ---
Layer search enabled: testing layers [16, 18, 20, 22, 24, 26, 28, 30]

============================================================
Testing Layer 16
============================================================
Running LOCAL extraction attack (per-question steering)...

--- Anonymization Check (Layer 16) ---
Original: What is the most important ball in Quidditch according to Wood?
  Anon0: What is the most important ball in Person A according to Person B?
  Anon1: What is the most important ball in Individual X according to Individual Y?
  Anon2: What is the most important ball in Character Alpha according to Character Beta?
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 21.3750
  Vector mean: 0.0055
  Vector std: 0.3340
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 11.5000
  Vector mean: 0.0008
  Vector std: 0.1797
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 8.2500
  Vector mean: 0.0001
  Vector std: 0.1289
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 7.2188
  Vector mean: 0.0012
  Vector std: 0.1128
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 15.3203
  Vector mean: -0.0046
  Vector std: 0.2394
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 6.6250
  Vector mean: -0.0004
  Vector std: 0.1035
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 7.8359
  Vector mean: 0.0005
  Vector std: 0.1224
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 11.5781
  Vector mean: -0.0014
  Vector std: 0.1809
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 10.0625
  Vector mean: 0.0016
  Vector std: 0.1572
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 13.9219
  Vector mean: -0.0040
  Vector std: 0.2175
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 20.8750
  Vector mean: 0.0032
  Vector std: 0.3262
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 12.6328
  Vector mean: 0.0000
  Vector std: 0.1974
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 8.5391
  Vector mean: -0.0005
  Vector std: 0.1335
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 7.2031
  Vector mean: -0.0025
  Vector std: 0.1125
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 6.3398
  Vector mean: -0.0018
  Vector std: 0.0991
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 18.0938
  Vector mean: 0.0044
  Vector std: 0.2827
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 14.7500
  Vector mean: -0.0047
  Vector std: 0.2305
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 9.2656
  Vector mean: -0.0019
  Vector std: 0.1448
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 0.0000
  Vector mean: 0.0000
  Vector std: 0.0000
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 16.9219
  Vector mean: -0.0003
  Vector std: 0.2644
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 19.3594
  Vector mean: 0.0054
  Vector std: 0.3025
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 13.7344
  Vector mean: 0.0020
  Vector std: 0.2146
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 10.3750
  Vector mean: 0.0036
  Vector std: 0.1621
  Computing activation differences...
  Steering vector computed from 1 question(s)
  Vector shape: torch.Size([4096])
  Vector norm: 13.8047
  Vector mean: -0.0006
  Vector std: 0.2157
